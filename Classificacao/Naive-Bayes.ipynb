{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmo Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "\n",
    "#data = pd.read_csv('data/vertebralcolumn-3C.csv')\n",
    "#data = pd.read_csv('data/BreastCancer.csv')\n",
    "data = pd.read_csv('data/Iris.csv')\n",
    "#data = pd.read_csv('data/Vehicle.csv')\n",
    "\n",
    "data = data.dropna(axis = 'rows') \n",
    "classes = np.array(pd.unique(data[data.columns[-1]]), dtype = str)  \n",
    "nrow, ncol = data.shape\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.to_numpy()\n",
    "y = data[:, -1]\n",
    "X = data[:, 0:ncol-1]\n",
    "\n",
    "scaler = MinMaxScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, train_size = 0.80, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para o cálculo da verossimilhança. \n",
    "\n",
    "def verossimilhanca(y, Z):\n",
    "    def gaussiana(x, mu, sig):\n",
    "        return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))\n",
    "    prob = 1\n",
    "    for j in np.arange(0, Z.shape[1]):\n",
    "        m = np.mean(Z[:,j])\n",
    "        s = np.std(Z[:,j])      \n",
    "        prob = prob*gaussiana(y[j], m, s)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente, definimos uma função para calcular a densidade de probabilidade conjunta: $$p(\\vec{x}|C_i) = \\prod_{j=1}^d p(x_j|C_i), \\quad i=1,\\ldots, k$$ \n",
    "onde $C_i$ são as classes. \n",
    "\n",
    "Se a distribuição for normal, temos que cada atributo $X_j$ tem a seguinte função densidade de probabilidade associada, para cada classe:\n",
    "$$\n",
    "p(x_j|C_i) = \\frac{1}{\\sqrt{2\\pi\\sigma_{C_i}}}\\exp \\left[ -\\frac{1}{2}\\left( \\frac{x_j-\\mu_{C_i}}{\\sigma_{C_i}}\\right)^2 \\right], \\quad i=1,2,\\ldots, k.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NB_gaussiano(x_train, x_test, y_train, y_test):\n",
    "    P = pd.DataFrame(data=np.zeros((x_test.shape[0], len(classes))), columns = classes) \n",
    "    for i in np.arange(0, len(classes)):\n",
    "        elements = np.where(y_train == classes[i])\n",
    "        Z = x_train[elements,:][0]\n",
    "        for j in np.arange(0, x_test.shape[0]):\n",
    "            x = x_test[j,:]\n",
    "            pj = verossimilhanca(x,Z)\n",
    "            P[classes[i]][j] = pj*len(elements)/x_train.shape[0]\n",
    "            \n",
    "    y_pred = []\n",
    "    for i in np.arange(0, P.shape[0]):\n",
    "        c = np.argmax(np.array(P.iloc[[i]]))\n",
    "        y_pred.append(P.columns[c])\n",
    "    y_pred = np.array(y_pred, dtype = str)\n",
    "    return y_pred "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimental "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['versicolor', 'virginica', 'virginica', 'setosa', 'virginica',\n",
       "       'versicolor', 'setosa', 'virginica', 'setosa', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'virginica', 'virginica', 'setosa',\n",
       "       'setosa', 'virginica', 'virginica', 'setosa', 'setosa',\n",
       "       'versicolor', 'virginica', 'setosa', 'versicolor', 'versicolor',\n",
       "       'virginica', 'versicolor', 'versicolor', 'versicolor', 'virginica'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = NB_gaussiano(x_train, x_test, y_train, y_test)\n",
    "y_test_prediction = np.asarray(y_test_pred)\n",
    "y_test_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Framework "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['versicolor', 'versicolor', 'virginica', 'setosa', 'virginica',\n",
       "       'versicolor', 'setosa', 'virginica', 'setosa', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'virginica', 'virginica', 'setosa',\n",
       "       'setosa', 'virginica', 'virginica', 'setosa', 'setosa',\n",
       "       'versicolor', 'virginica', 'setosa', 'versicolor', 'versicolor',\n",
       "       'virginica', 'versicolor', 'versicolor', 'versicolor', 'virginica'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GaussianNB()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparando os resultados do modelo contruído vs o modelo do sklearn. \n",
    "y_test_prediction == y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Autor**: Alan Gomes \n",
    "\n",
    "**E-mail**: gomes-alan@hotmail.com \n",
    "\n",
    "#### Referências \n",
    "\n",
    "[1] Curso de ciência de dados do professor Dr. Francisco Rodrigues - USP\n",
    "- https://www.youtube.com/watch?v=lm2IagDGDAU&list=PLSc7xcwCGNh1PJrPfLaH4MMjfDl48tmGM\n",
    "\n",
    "[2] Curso Machine Learning - Data Science Academy "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
